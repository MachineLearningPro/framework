{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implement_linear import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_path=\"train.csv\"\n",
    "test_path=\"test.csv\"\n",
    "name=\"discrimination_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb_train,data_train,ids_train=load_csv_data(train_path, sub_sample=False)\n",
    "#yb_test,data_test,ids_test=load_csv_data(test_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  主函数的主体在这里\n",
    "    \n",
    "def main(data_train,yb_train,choice,degree,lambda_,gamma):\n",
    "    train_size=100000;\n",
    "    data_train_copy=data_train.copy()\n",
    "    print('Started the run!\\n')\n",
    "    \n",
    "    yb_train,data_train,ids_train=load_csv_data(train_path, sub_sample=False)\n",
    "    #yb_test,data_test,ids_test=load_csv_data(test_path, sub_sample=False)\n",
    "    data_train_copy=data_train.copy()\n",
    "    print('Finished loading data!\\n')   \n",
    "    \n",
    "\n",
    "    print('Feature restore...')\n",
    "   \n",
    "    # data_train,u_s,u_b=restore_train_first_or_none_and_second(yb_train,data_train,train_size,1)\n",
    "   #data_train=restore_train_initial(yb_train,data_train,train_size)\n",
    "   \n",
    "    # data_train=restore_test_first_or_none(yb_train,data_train,train_size)\n",
    "    # data_train=restore_test_all_b_s(yb_train,data_train,train_size,u_s)\n",
    "    \n",
    "    print('Feature processing...\\n')\n",
    "   # mean_x = np.mean(data_train,0)\n",
    "   # data_train = data_train - mean_x\n",
    "    #std_x = np.std(data_train,0)\n",
    "   # data_train = data_train / std_x\n",
    "    \n",
    "    data_train=add_feature(data_train)\n",
    "    \n",
    "    \n",
    "    #data_train=drop_feature(data_train)\n",
    "    #degree=3\n",
    "    #a22_value=0;\n",
    "    #data_train=drop_feature(data_train)\n",
    "    #yb_train,data_train=drop_22(a22_value,yb_train,data_train)\n",
    "    #drop_22(2,yb_test,data_test)\n",
    "    #add_feature(data_train)\n",
    "    #add_feature(data_test)\n",
    "    data_train=build_model_data(data_train,degree)\n",
    "    #drop_feature(data_test)    \n",
    "    print('Training begin...\\n')\n",
    "    #train_size=1000;\n",
    "\n",
    "    if choice==1:\n",
    "        w,loss=train_normal(yb_train,data_train,train_size)\n",
    "    \n",
    "    elif choice==2:\n",
    "        w,loss=train_ridge(yb_train, data_train, train_size,lambda_)\n",
    "    \n",
    "    elif choice==3:\n",
    "        w,loss=train_gradient(yb_train, data_train, train_size)\n",
    "    \n",
    "    elif choice==4:\n",
    "        w,loss=train_logistic(yb_train, data_train,gamma,train_size)\n",
    "        \n",
    "    elif choice==5:\n",
    "        w,loss=train_gradient_SGD(yb_train, data_train, train_size)\n",
    "    \n",
    "    print(\"loss\")\n",
    "    print(loss)\n",
    "    print(\"\\n\")\n",
    "   # print(w)\n",
    "    print('Testing begin...\\n')\n",
    "    #data_train=destroy(yb_train,data_train)\n",
    "    yb_pred,yb_id=test(yb_train,data_train,w,train_size,data_train_copy)\n",
    "    #yb_initial=yb_test.copy()\n",
    "    sign1=yb_pred+yb_id\n",
    "    sign2=yb_pred-yb_id\n",
    "    ratio=len(sign1[sign1==2])/len(sign2[sign2==2])\n",
    "    return \n",
    "    \n",
    "    # 之后的代码没有用了，不用管\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data_train,u_s,u_b=restore_train_first_or_none_and_second(yb_train,data_train_copy,train_size,1)\n",
    "    data_train=add_feature(data_train)\n",
    "    data_train=build_model_data(data_train,degree)\n",
    "    w1,loss=train_normal(yb_train,data_train,train_size)\n",
    "    \n",
    "    #return yb_test\n",
    "    maxiter=2;\n",
    "    i=0\n",
    "    while i<maxiter:\n",
    "        print('Feature restore...')\n",
    "        data_train=restore_test_second(yb_pred,data_train_copy,train_size,u_s,u_b)\n",
    "       # print('Feature Finished!\\n')\n",
    "        data_train=add_feature(data_train)\n",
    "        data_train=build_model_data(data_train,degree)\n",
    "        \n",
    "        print('Testing begin...\\n')    \n",
    "        yb_pred=test(yb_train,data_train,w1,train_size,data_train_copy)\n",
    "        i+=1\n",
    "    #print(w)\n",
    "    #test_sub(yb_test,data_test,w,ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  具体的子函数，很多现在没有用了\n",
    "def train_normal(yb_train, data_train,train_size):\n",
    "    yb_train=yb_train[:train_size]\n",
    "    data_train=data_train[:train_size]\n",
    "    w,loss=least_squares(yb_train,data_train)\n",
    "    return w,loss\n",
    "\n",
    "def train_ridge(yb_train, data_train, lambda_,train_size):\n",
    "    #lambda_=10\n",
    "    yb_train=yb_train[:train_size]\n",
    "    data_train=data_train[:train_size]\n",
    "    w,loss=ridge_regression(yb_train, data_train, lambda_)\n",
    "    return w,loss\n",
    "\n",
    "def train_gradient(yb_train, data_train, train_size):\n",
    "    max_iters = 100\n",
    "    gamma = 1e-9\n",
    "    initial_w=np.zeros(len(data_train.T));\n",
    "    yb_train=yb_train[:train_size]\n",
    "    data_train=data_train[:train_size]\n",
    "    w,loss=least_squares_GD(yb_train, data_train, initial_w, max_iters, gamma)\n",
    "    return w,loss\n",
    "\n",
    "def train_logistic(yb_train,data_train,gamma,train_size,):\n",
    "    initial_w=np.ones(len(data_train.T));\n",
    "    max_iters=300;\n",
    "    #gamma=1e-7;\n",
    "    yb_train=yb_train[:train_size]\n",
    "    data_train=data_train[:train_size]\n",
    "    w,loss=logistic_regression(yb_train, data_train, initial_w, max_iters, gamma)\n",
    "    return w,loss\n",
    "\n",
    "def train_gradient_SGD(yb_train, data_train,train_size):\n",
    "    batch_size=1;\n",
    "    max_iters = 50\n",
    "    gamma = 1e-8\n",
    "    initial_w=np.zeros(len(data_train.T));\n",
    "    yb_train=yb_train[:train_size]\n",
    "    data_train=data_train[:train_size]\n",
    "    w,loss=least_squares_SGD(yb_train, data_train, initial_w, max_iters, gamma,batch_size)\n",
    "    return w,loss\n",
    "\n",
    "def test(yb_train,data_train,w,train_size,data_train_copy):\n",
    "    yb_train=yb_train[train_size:]\n",
    "    data_train=data_train[train_size:]\n",
    "    data_train_copy=data_train_copy[train_size:]\n",
    "    #y_pred=predict_labels(w, data_train)\n",
    "    \n",
    "    score = np.dot(data_train, w)\n",
    "    y_pred=score.copy()\n",
    "    y_pred[np.where(y_pred <= 0)] = -1\n",
    "    y_pred[np.where(y_pred > 0)] = 1\n",
    "    y_pred[np.where(data_train_copy[:,0]==-999)]=-1\n",
    "    recall,precision,accuracy=performance(y_pred,yb_train)\n",
    "    print(\"recall\")\n",
    "    print(recall)\n",
    "    print(\"precision\")\n",
    "    print(precision)\n",
    "    print(\"accuracy\")\n",
    "    print(accuracy)\n",
    "    print(\"s%\")\n",
    "    print(33*recall*precision)\n",
    "    return y_pred,yb_train\n",
    "\n",
    "def test_sub(yb_test,data_test,w,ids_test):\n",
    "    y_pred=predict_labels(w, data_test)\n",
    "    create_csv_submission(ids_test, y_pred, name)\n",
    "    recall,precision,accuracy=performance(y_pred,yb_test)\n",
    "    print(\"recall\")\n",
    "    print(recall)\n",
    "    \n",
    "    \n",
    "def restore_train_first_or_none_and_second(yb,data,train_size,maxiter):\n",
    "    yb_train=yb[:train_size]\n",
    "    data_train=data[:train_size]\n",
    "   # yb_train=yb;\n",
    "   # data_train=data;\n",
    "    \n",
    "    data_s=data_train[yb_train==1]\n",
    "    data_b=data_train[yb_train==-1]\n",
    "    \n",
    "    u_s=np.zeros(len(data_s))\n",
    "    u_b=np.zeros(len(data_b))\n",
    "    for i in range(len(data_train.T)):\n",
    "        slice_s=data_s[:,i]\n",
    "        u_s[i]=np.mean(slice_s[slice_s!=-999])\n",
    "        slice_s[np.where(slice_s==-999)]=u_s[i]\n",
    "        \n",
    "        slice_b=data_b[:,i]\n",
    "        u_b[i]=np.mean(slice_b[slice_b!=-999])\n",
    "        slice_b[np.where(slice_b==-999)]=u_b[i]\n",
    "        \n",
    "    data_train[yb_train==1]=data_s\n",
    "    data_train[yb_train==-1]=data_b\n",
    "    #print(\"iter_=\");\n",
    "    #print(iter_);\n",
    "    #print(np.abs(u_s_new-u_b_new)/u_s_new);\n",
    "    return data,u_s,u_b\n",
    "\n",
    "def restore_train_initial(yb,data,train_size):\n",
    "\n",
    "    yb_train=yb[train_size:]\n",
    "    data_train=data[train_size:]\n",
    "    \n",
    "    maxiter=1;\n",
    "    iter_=0;\n",
    "    u_old=np.ones(len(data_train.T))*-999\n",
    "    err=10;\n",
    "    #data_short=\n",
    "    u=np.mean(data_train,0)\n",
    "    #data_s=data_train[yb_train==1]\n",
    "    #data_b=data_train[yb_train==-1]\n",
    "    #u_s=np.mean(data_s,0)\n",
    "    #u_b=np.mean(data_b,0)\n",
    "    \n",
    "    while iter_<maxiter and err>1e-2:\n",
    "        u_new=np.mean(data_train,0)\n",
    "        for i in range(len(data_train.T)):\n",
    "            slice_=data_train[:,i]\n",
    "            slice_[np.where(slice_==u_old[i])]=u_new[i]\n",
    "        err=np.linalg.norm(np.linalg.norm(np.abs(u_new-u_old)/u_new))\n",
    "        u_old=u_new\n",
    "        iter_+=1\n",
    "    #print(\"iter_=\");\n",
    "    #print(iter_);\n",
    "   # print(np.abs(u_new-u)/u_new);\n",
    "    return data\n",
    "\n",
    "def restore_test_first_or_none(yb,data,train_size):\n",
    "\n",
    "    yb_test=yb[train_size:]\n",
    "    data_test=data[train_size:]\n",
    "    #data_s=data_train[yb_train==1]\n",
    "    #data_b=data_train[yb_train==-1]\n",
    "    #u_s=np.mean(data_s,0)\n",
    "    #u_b=np.mean(data_b,0)\n",
    "    for i in range(len(data_test.T)):\n",
    "        #slice_=data_s[:,i]\n",
    "        #slice_[np.where(slice_==-999)]=u_s[i]\n",
    "        #slice_=data_b[:,i]\n",
    "        #slice_[np.where(slice_==-999)]=u_b[i]\n",
    "        slice_=data_test[:,i]\n",
    "        \n",
    "        u=np.mean(slice_[slice_!=-999])\n",
    "        slice_[np.where(slice_==-999)]=u\n",
    "    #data_train[yb==1]=data_s\n",
    "    #data_train[yb==-1]=data_b\n",
    "    return data\n",
    "\n",
    "def restore_test_second(yb,data,train_size,u_s,u_b):\n",
    "    \n",
    "    yb_test=yb;\n",
    "    #yb_test=yb[train_size:]\n",
    "    data_test=data[train_size:]\n",
    "    \n",
    "    data_s=data_test[yb_test==1]\n",
    "    data_b=data_test[yb_test==-1]\n",
    "    for i in range(len(data_test.T)):\n",
    "        #slice_=data_s[:,i]\n",
    "        #slice_[np.where(slice_==-999)]=u_s[i]\n",
    "        #slice_=data_b[:,i]\n",
    "        #slice_[np.where(slice_==-999)]=u_b[i]\n",
    "        slice_s=data_s[:,i]\n",
    "        slice_s[np.where(slice_s==-999)]=u_s[i]\n",
    "        \n",
    "        slice_b=data_b[:,i]\n",
    "        slice_b[np.where(slice_b==-999)]=u_b[i]\n",
    "    data_test[yb_test==1]=data_s\n",
    "    data_test[yb_test==-1]=data_b\n",
    "    return data\n",
    "\n",
    "def restore_test_all_b_s(yb,data,train_size,value):\n",
    "\n",
    "    yb_test=yb[train_size:]\n",
    "    data_test=data[train_size:]\n",
    "    #data_s=data_train[yb_train==1]\n",
    "    #data_b=data_train[yb_train==-1]\n",
    "    #u_s=np.mean(data_s,0)\n",
    "    #u_b=np.mean(data_b,0)\n",
    "    for i in range(len(data_test.T)):\n",
    "        slice_=data_test[:,i]\n",
    "        slice_[np.where(slice_==-999)]=value[i]\n",
    "    #data_train[yb==1]=data_s\n",
    "    #data_train[yb==-1]=data_b\n",
    "    return data\n",
    "\n",
    "def drop_feature(data):\n",
    "\n",
    "    #data=np.delete(data,range(23,29),1)\n",
    "    data=np.delete(data,20,1)\n",
    "    data=np.delete(data,range(17,18),1)    \n",
    "    data=np.delete(data,range(15,17),1)\n",
    "    #data=np.delete(data,12,1)\n",
    "    data=np.delete(data,7,1)   \n",
    "    data=np.delete(data,3,1) \n",
    "    #data=np.delete(data,range(4,7),1)\n",
    "    \n",
    "#r_data=np.delete(r_data,17,1)\n",
    "#r_data=np.delete(r_data,18,1)\n",
    "\n",
    "\n",
    "#r_data=np.delete(r_data,25,1)\n",
    "#r_data=np.delete(r_data,25,1)\n",
    "#r_data=np.delete(r_data,28,1)\n",
    "#r_data=np.delete(r_data,29,1)\n",
    "    return data\n",
    "\n",
    "def drop_22(a22_value,yb,data):\n",
    "    data_=data[data[:,22]==a22_value]\n",
    "    yb_=yb[data[:,22]==a22_value]\n",
    "    data_=np.delete(data_,22,1)\n",
    "    return yb_,data_\n",
    "\n",
    "def add_feature(data):\n",
    "    r_data=data.copy()#np.c_[tx,x**(i+1)]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,4])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,6])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,7])]\n",
    "    #r_data=np.c_[r_data,np.exp(data[:,11])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,12])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,14])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,15])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,24])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,18])]\n",
    "    #r_data=np.c_[r_data,np.exp(data[:,11])]\n",
    "    #r_data=np.c_[r_data,np.exp(data[:,27])]\n",
    "    #r_data=np.c_[r_data,np.exp(data[:,27])]\n",
    "\n",
    "    r_data=np.c_[r_data,np.cos(data[:,10])]\n",
    "    r_data=np.c_[r_data,np.cos(data[:,24])]\n",
    "    r_data=np.c_[r_data,np.cos(data[:,27])]\n",
    "\n",
    "    r_data=np.c_[r_data,np.cos(data[:,11])]\n",
    "    r_data=np.c_[r_data,np.log(data[:,9])]\n",
    "\n",
    "    r_data=np.c_[r_data,np.log(data[:,10])]\n",
    "    r_data=np.c_[r_data,np.log(data[:,13])]\n",
    "    r_data=np.c_[r_data,np.log(data[:,19])]\n",
    "\n",
    "    #r_data=np.c_[r_data,data[:,3]*data[:,9]]\n",
    "    #r_data=np.c_[r_data,data[:,2]*data[:,19]]\n",
    "    #r_data=np.c_[r_data,data[:,22]*data[:,12]]\n",
    "    #for i in range(len(data.T)-10):\n",
    "   # for j in range(i+10,len(data.T)):\n",
    "     #       r_data=np.c_[r_data,data[:,i]*data[:,i+10]]\n",
    "    \n",
    "    r_data=np.c_[r_data,data[:,range(7,10)]**5]\n",
    "#r_data=np.c_[r_data,1/data[:,9]]\n",
    "#r_data=np.c_[r_data,1/data[:,26]]\n",
    "\n",
    "#r_data=np.c_[r_data,np.log(data[:,19])]\n",
    "#r_data=np.c_[r_data,np.log(data[:,20])]\n",
    "#r_data=np.c_[r_data,np.sin(data[:,11])]\n",
    "#r_data=np.c_[r_data,np.exp(data[:,10])]\n",
    "    return r_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started the run!\n",
      "\n",
      "Finished loading data!\n",
      "\n",
      "Feature restore...\n",
      "Feature processing...\n",
      "\n",
      "Training begin...\n",
      "\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1eb1f691937e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#gamma=1e-7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#[1e-10,1e-8,1e-7,1e-6]:#[1e-7,1e-5,1e-2,1,100]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-1a7d55be6acd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_train, yb_train, choice, degree, lambda_, gamma)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_ridge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1a7d55be6acd>\u001b[0m in \u001b[0;36mtrain_ridge\u001b[0;34m(yb_train, data_train, lambda_, train_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0myb_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myb_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdata_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/labs/project_1/implement_linear.py\u001b[0m in \u001b[0;36mridge_regression\u001b[0;34m(y, tx, lambda_)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "#   主函数在这里\n",
    "#  choice=1  对应运行 train_normal equation  模型进行训练\n",
    "#  choice=2  对应运行 train_ridge regression 模型进行训练\n",
    "#  choice=3   其他的暂时有bug\n",
    "\n",
    "choice=2\n",
    "degree=1\n",
    "lambda_=0\n",
    "#gamma=1e-7\n",
    "for gamma in [1e-9,1e-5,1e-2,1,100]:#[1e-10,1e-8,1e-7,1e-6]:#[1e-7,1e-5,1e-2,1,100]:\n",
    "    main(data_train,yb_train,choice,degree,lambda_,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
