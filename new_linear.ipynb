{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_implement_linear import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_path=\"train.csv\"\n",
    "test_path=\"test.csv\"\n",
    "name=\"discrimination_submission.csv\"\n",
    "\n",
    "yb_train,data_train,ids_train=load_csv_data(train_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_evaluation(data_train, yb_train, opt_model, cros_vali, degree, lambda_, gamma, outlier, method):\n",
    "    \n",
    "    seed = np.random.randint(cros_vali*100)\n",
    "    \n",
    "    print('step 1:Started main function!')\n",
    "    data_train_copy = data_train.copy() \n",
    "    \n",
    "    print('step 2:Feature augmentaion...')\n",
    "    data_train = add_feature(data_train)            # add log and exp\n",
    "    data_train = build_model_data(data_train, degree)  # add x^n\n",
    "    \n",
    "    print('step 3:Cross validation begins...')\n",
    "    indices = build_k_indices(yb_train, cros_vali, seed) \n",
    "    corrections = cross_validation(data_train, yb_train, indices, opt_model, lambda_, outlier, method)\n",
    "    \n",
    "    print('step 7:End of Trainging\\n')\n",
    "\n",
    "    return np.mean(corrections)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unified model choose\n",
    "def train_mode(train_x, train_y, chosen_model, lambda_):\n",
    "    if chosen_model   == 1:     \n",
    "        w,loss=train_normal(train_y,train_x)\n",
    "    \n",
    "    elif chosen_model == 2:\n",
    "        w,loss=train_ridge(train_y, train_x, lambda_)\n",
    "    \n",
    "    elif chosen_model == 3:\n",
    "        w,loss=train_gradient(train_y, train_x)\n",
    "    \n",
    "    elif chosen_model == 4:\n",
    "        w,loss=train_logistic(train_y, train_x, gamma)\n",
    "        \n",
    "    elif chosen_model == 5:\n",
    "        w,loss=train_gradient_SGD(train_y, train_x)\n",
    "                                   \n",
    "#     elif chosen_model == 6:\n",
    "        \n",
    "    elif chosen_model == 7:\n",
    "        class_1 = train_x[train_y == -1][:,1:train_x.shape[1]]\n",
    "        class_2 = train_x[train_y == +1][:,1:train_x.shape[1]]\n",
    "        \n",
    "        w, loss = Fisher_classifier(class_1, class_2)\n",
    "        \n",
    "    return w, loss\n",
    "\n",
    "\n",
    "# optimization models\n",
    "def train_normal(yb_train, data_train):\n",
    "    w,loss=least_squares(yb_train,data_train)\n",
    "    return w,loss\n",
    "\n",
    "def train_ridge(yb_train, data_train, lambda_):\n",
    "    w,loss=ridge_regression(yb_train, data_train, lambda_)\n",
    "    return w,loss\n",
    "\n",
    "def train_gradient(yb_train, data_train, step_size):\n",
    "    max_iters = 100\n",
    "    gamma = step_size\n",
    "    initial_w=np.zeros(len(data_train.T));\n",
    "    w,loss=least_squares_GD(yb_train, data_train, initial_w, max_iters, gamma)\n",
    "    return w,loss\n",
    "\n",
    "def train_logistic(yb_train, data_train, step_size):\n",
    "    initial_w=np.ones(len(data_train.T));\n",
    "    max_iters=300;\n",
    "    gamma=step_size;\n",
    "    w,loss=logistic_regression(yb_train, data_train, initial_w, max_iters, gamma)\n",
    "    return w,loss\n",
    "\n",
    "def train_gradient_SGD(yb_train, data_train, step_size):\n",
    "    batch_size=1;\n",
    "    max_iters = 50\n",
    "    gamma = step_size\n",
    "    initial_w=np.zeros(len(data_train.T));\n",
    "    w,loss=least_squares_SGD(yb_train, data_train, initial_w, max_iters, gamma,batch_size)\n",
    "    return w,loss\n",
    "\n",
    "# reserved def\n",
    " \n",
    "\n",
    "def Fisher_classifier(class_1, class_2):\n",
    "    # means\n",
    "    m_1 = np.mean(class_1, axis = 0)\n",
    "    m_2 = np.mean(class_2, axis = 0)\n",
    "    \n",
    "    # inner class1 dispersion\n",
    "    S_1 = (class_1 - m_1).T.dot(class_1 - m_1)\n",
    "    # inner class2 dispersion\n",
    "    S_2 = (class_2 - m_2).T.dot(class_2 - m_2)\n",
    "    # seperating level\n",
    "    S_W = S_1 + S_2\n",
    "    \n",
    "    # perpendicular vector of the separating hyperplane\n",
    "    w_star = np.linalg.inv(S_W.astype(float)).dot(m_2 - m_1)\n",
    "    \n",
    "    mapped_b = class_1.dot(w_star)\n",
    "    m_t_b = mapped_b.mean()\n",
    "    mapped_s = class_2.dot(w_star)\n",
    "    m_t_s = mapped_s.mean()\n",
    "\n",
    "    # intersection point of the separating hyperplane and the perpendicular vector \n",
    "    w0 = -0.5*(m_t_b + m_t_s)\n",
    "    \n",
    "    return np.insert(w_star, 0, w0), np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_feature(data):\n",
    "    r_data=data.copy()\n",
    "    r_data=np.c_[r_data,np.exp(data[:,4])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,6])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,7])]\n",
    "\n",
    "    r_data=np.c_[r_data,np.exp(data[:,12])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,14])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,15])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,24])]\n",
    "    r_data=np.c_[r_data,np.exp(data[:,18])]\n",
    "\n",
    "    r_data=np.c_[r_data,np.cos(data[:,10])]\n",
    "    r_data=np.c_[r_data,np.cos(data[:,24])]\n",
    "    r_data=np.c_[r_data,np.cos(data[:,27])]\n",
    "\n",
    "    r_data=np.c_[r_data,np.cos(data[:,11])]\n",
    "    r_data=np.c_[r_data,np.log(data[:,9])]\n",
    "\n",
    "    r_data=np.c_[r_data,np.log(data[:,10])]\n",
    "    r_data=np.c_[r_data,np.log(data[:,13])]\n",
    "    r_data=np.c_[r_data,np.log(data[:,19])]\n",
    "\n",
    "    r_data=np.c_[r_data,data[:,range(7,10)]**5]\n",
    "\n",
    "    return r_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(train_x, train_y, test_x, method, outlier):\n",
    "\n",
    "    if method == 'no':\n",
    "        print('No data processing is conducted')\n",
    "    \n",
    "    else:\n",
    "        # replace outliers by nan\n",
    "        if ~np.isnan(outlier):\n",
    "            train_x[train_x == outlier] = np.nan\n",
    "            test_x [test_x  == outlier] = np.nan\n",
    "        else:\n",
    "            print('No need to replace outlies by nan!\\n')\n",
    "\n",
    "        if method == 'mean':\n",
    "            \n",
    "            # only nan is replaced by mean value here\n",
    "            train_x = fill_mean(train_x, train_y, 'train_data')\n",
    "            test_x  = fill_mean(test_x , []     , 'test_data' )\n",
    "            \n",
    "        elif method == 'normalization':\n",
    "            \n",
    "            # To normalization, filling mean is necessary\n",
    "            \n",
    "            train_x = fill_mean(train_x, train_y, 'train_data')\n",
    "            test_x  = fill_mean(test_x , []     , 'test_data' )\n",
    "            \n",
    "            train_x = normalization(train_x, train_y, 'train_data')      \n",
    "            test_x  = normalization(test_x , []     , 'test_data' )\n",
    "    \n",
    "    \n",
    "        elif method == 'drop':\n",
    "            to_drop_train = np.isnan(train_x.min(axis = 0))\n",
    "            to_drop_test  = np.isnan( test_x.min(axis = 0))\n",
    "            to_drop = to_drop_train | to_drop_test\n",
    "            \n",
    "            train_x = train_x[:, ~to_drop]\n",
    "            test_x  = test_x [:, ~to_drop]\n",
    "            \n",
    "        else:\n",
    "            print('No such processing method! Please check your input!')\n",
    "            return -1\n",
    "        \n",
    "    return train_x, test_x  \n",
    "\n",
    "\n",
    "def fill_mean(data, label, category):\n",
    "    \n",
    "    if category == 'train_data':\n",
    "        class_1 = data[label == 1 ]\n",
    "        class_2 = data[label == -1]\n",
    "        \n",
    "        mean_1 = np.nanmean(class_1,axis = 0)\n",
    "        mean_2 = np.nanmean(class_2,axis = 0)\n",
    "        \n",
    "        for ct_i in range(class_1.shape[1]):\n",
    "            class_1[ np.isnan(class_1[:,ct_i]), ct_i] = mean_1[ct_i]\n",
    "            class_2[ np.isnan(class_2[:,ct_i]), ct_i] = mean_2[ct_i]\n",
    "        \n",
    "        data[label == 1 ] = class_1\n",
    "        data[label == -1] = class_2\n",
    "        \n",
    "    elif category == 'test_data':\n",
    "        mean = np.nanmean(data,axis = 0)     \n",
    "        for ct_i in range(data.shape[1]):\n",
    "            data[ np.isnan(data[:,ct_i]), ct_i] = mean[ct_i]\n",
    "            \n",
    "    else:\n",
    "        print('No such data category! Please check your input!')\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def normalization(data, label, category):\n",
    "    \n",
    "    eps = 1e-2\n",
    "    \n",
    "    if category == 'train_data':\n",
    "        class_1 = data[label == 1, 1:data.shape[1] ]\n",
    "        class_2 = data[label == -1, 1:data.shape[1]]\n",
    "        \n",
    "        class_1 = (class_1 - np.nanmin(class_1,axis=0))/(np.nanmax(class_1,axis=0) - np.nanmin(class_1,axis=0) + eps)\n",
    "        class_2 = (class_2 - np.nanmin(class_2,axis=0))/(np.nanmax(class_2,axis=0) - np.nanmin(class_2,axis=0) + eps)   \n",
    "        \n",
    "        data[label == 1, 1:data.shape[1] ] = class_1\n",
    "        data[label == -1, 1:data.shape[1]] = class_2\n",
    "                \n",
    "    elif category == 'test_data':\n",
    "        data_temp = data[:, 1:data.shape[1]].copy()\n",
    "        data_temp = (data_temp - np.nanmin(data_temp,axis=0))/(np.nanmax(data_temp,axis=0) - np.nanmin(data_temp,axis=0) + eps)\n",
    "\n",
    "        data[:, 1:data.shape[1]] = data_temp.copy()\n",
    "    else:\n",
    "        print('No such data category! Please check your input!')\n",
    "        \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "\n",
    "def cross_validation(feature, lable, indices, opt_model, lambda_, outlier, method):\n",
    "    '''cross validation to evaluate performance of a given mode.\n",
    "    \n",
    "       feature (ndarray)  : feature vectors\n",
    "       lable   (array)    : lable of every row of feature\n",
    "       indices            : grouped indices of the dataset\n",
    "       opt_model(int)     : chosen classification model \n",
    "    '''\n",
    "    \n",
    "    iter_times = indices.shape[0]\n",
    "    correction = []\n",
    "    \n",
    "    for ct_iter in range(iter_times):\n",
    "        # produce training data\n",
    "        train_x = feature[indices[ct_iter]]\n",
    "        train_y = lable[indices[ct_iter]]\n",
    "        \n",
    "        # produce testing data\n",
    "        test_indices = indices[np.arange(indices.shape[0])!=ct_iter]\n",
    "        test_indices = test_indices.ravel()\n",
    "        test_x = feature[test_indices]\n",
    "        test_y = lable[test_indices]\n",
    "        \n",
    "        print('  -> Data processing:', method)\n",
    "        train_x, test_x = data_process(train_x, train_y, test_x, method, outlier)\n",
    "        \n",
    "        w, loss = train_mode(train_x, train_y, opt_model, lambda_)\n",
    "        prediction = predict_labels(w, test_x)\n",
    "            \n",
    "        correction.append( sum(prediction == test_y.astype(float))/test_y.shape[0] )\n",
    "            \n",
    "        print('          --** Accuracy of cross validation', ct_iter, 'is:', correction[ct_iter])\n",
    "    return correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.77111\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.76952\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.769815\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.769315\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.76956\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.77075\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.768585\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.771775\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.768255\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.770745\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.76994\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.76995\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.76909\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.76985\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.770475\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.768795\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.76954\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.770835\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.77045\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.769795\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.770015\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.769815\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.77012\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.769735\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.7704\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.77019\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.769305\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.771425\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.76881\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.77002\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.77031\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.768535\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.77052\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.769725\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.77042\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.7686\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.770065\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.77113\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.77074\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.76949\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.77005\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.76876\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.77054\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.769705\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.770295\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.77026\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.77044\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.768835\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.76964\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.76886\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.7677\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.770445\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.768965\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.76834\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.76838\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.765695\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.766875\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.76633\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.76575\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.766055\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.76254\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.762485\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.762025\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.762255\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.76346\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.75948\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.76017\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.760655\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.75935\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.759835\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.75743\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.75661\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.75934\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.758185\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.756595\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.754185\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.755435\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.7558\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.754935\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.75541\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.751525\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.750105\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.749605\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.75066\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.749035\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.743455\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.742095\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.74187\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.74223\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.741555\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.735975\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.734475\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.734695\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.735145\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.733575\n",
      "step 7:End of Trainging\n",
      "\n",
      "step 1:Started main function!\n",
      "step 2:Feature augmentaion...\n",
      "step 3:Cross validation begins...\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 0 is: 0.731925\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 1 is: 0.73035\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 2 is: 0.730255\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 3 is: 0.730825\n",
      "  -> Data processing: drop\n",
      "          --** Accuracy of cross validation 4 is: 0.729615\n",
      "step 7:End of Trainging\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main function here\n",
    "\n",
    "#  algrithm=1  Least Squrare\n",
    "#  algrithm=2  Ridge Regression\n",
    "#  algrithm=3   其他的暂时有bug\n",
    "#  ...\n",
    "#  algrithm=7  Fisher Linear Discriminant\n",
    "\n",
    "outlier = -999\n",
    "method =  'drop' #  all methods: 'mean', 'normalization', 'drop', 'no'\n",
    "\n",
    "algrithm = 2\n",
    "cros_slice = 5\n",
    "degree = 1\n",
    "lambda_= np.logspace(-10, 1, num = 20, endpoint=True) \n",
    "gamma = 0.1 # step_size\n",
    "\n",
    "mean_correct = np.zeros(len(lambda_))\n",
    "\n",
    "for ct_i in range(len(lambda_)):\n",
    "    mean_correct[ct_i] = algorithm_evaluation(data_train    , yb_train, \n",
    "                                              algrithm      , cros_slice, \n",
    "                                              degree        , lambda_[ct_i], \n",
    "                                              gamma         , outlier, \n",
    "                                              method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.plot(lambda_, mean_correct)\n",
    "\n",
    "plt.xlabel('Ridge regression coefficients ')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['coefficiency'])\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('Ridge regression coefficiency.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(degree, mean_correct)\n",
    "plt.xlabel('Polynomial feature augmentation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Accuracy'])\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('Least square with different dgree.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
